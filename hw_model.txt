Loading layer x to dp0_server1[0], gpu1[0]
Loading layer conv1 to dp0_server1[1], gpu1[1]
Loading layer bn1 to dp0_server1[2], gpu1[2]
Loading layer relu to dp0_server1[3], gpu1[3]
Loading layer maxpool to dp0_server1[4], gpu2[0]
Loading layer layer1_0_conv1 to dp0_server1[5], gpu2[1]
Loading layer layer1_0_bn1 to dp0_server1[6], gpu2[2]
Loading layer layer1_0_relu to dp0_server1[7], gpu2[3]
Loading layer layer1_0_conv2 to dp0_server1[8], gpu3[0]
Loading layer layer1_0_bn2 to dp0_server1[9], gpu3[1]
Loading layer layer1_0_relu_1 to dp0_server1[10], gpu3[2]
Loading layer layer1_0_conv3 to dp0_server1[11], gpu3[3]
Loading layer layer1_0_bn3 to dp0_server1[12], gpu4[0]
Loading layer layer1_0_downsample_0 to dp0_server1[13], gpu4[1]
Loading layer layer1_0_downsample_1 to dp0_server2[0], gpu1[0]
Loading layer add to dp0_server2[1], gpu1[1]
Loading layer layer1_0_relu_2 to dp0_server2[2], gpu1[2]
Loading layer layer1_1_conv1 to dp0_server2[3], gpu2[0]
Loading layer layer1_1_bn1 to dp0_server2[4], gpu2[1]
Loading layer layer1_1_relu to dp0_server2[5], gpu3[0]
Loading layer layer1_1_conv2 to dp0_server2[6], gpu3[1]
Loading layer layer1_1_bn2 to dp0_server2[7], gpu3[2]
Loading layer layer1_1_relu_1 to dp0_server2[8], gpu4[0]
Loading layer layer1_1_conv3 to dp0_server2[9], gpu4[1]
Loading layer layer1_1_bn3 to dp0_server2[10], gpu4[2]
Loading layer add_1 to dp0_server2[11], gpu4[3]
    global_index  layer_index                   name                                   args  input_#  output_#  Param_#  dp_index  pp_index  tp_index         opcode                   target   layer_type                     input_shape                    output_shape                  param_shape                                                                                                           kwargs  dtype_size direction  avg_mem_grp_idx  avg_mem_grp_size  min_comm_grp_id  min_comm_grp_sum  min_comm_grp_last_weight  compute_density_ops    server_id gpu_id  index_on_host  index_on_GPU input_source output_dest  prev_server prev_gpu  next_server next_gpu     read_time     exec_time    write_time
0            100            0                      x                                     ()      100       100        0         0         0         0    placeholder                        x         None   torch.Size([32, 3, 224, 224])  torch.Size([32, 64, 112, 112])                         None                                                                                                             None           4       FWD                0                 0                0                 0                         0                10000  dp0_server1   gpu1              0             0         host         HBM         None     None  dp0_server1     gpu1  5.820766e-09  5.128205e-10  2.395685e-10
1            101            1                  conv1                                   (x,)     7840    576000      576         0         0         0    call_module                    conv1       Conv2d  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])    torch.Size([64, 3, 7, 7])                                                             {'stride': (2, 2), 'padding': (3, 3), 'bias': False}           4       FWD                0                 0                0                 0                         0                11000  dp0_server1   gpu1              1             1          HBM         HBM  dp0_server1     gpu1  dp0_server1     gpu1  1.878217e-08  5.641026e-10  1.379915e-06
2            102            2                    bn1                               (conv1,)   576000    576000      128         0         0         0    call_module                      bn1  BatchNorm2d  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                0                 0                0                 0                         0                12000  dp0_server1   gpu1              2             2          HBM         HBM  dp0_server1     gpu1  dp0_server1     gpu1  1.379915e-06  6.153846e-10  1.379915e-06
3            103            3                   relu                                 (bn1,)   576000    576000        0         0         0         0    call_module                     relu         ReLU  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])                         None                                                                                                {'inplace': True}           4       FWD                0                 0                0                 0                         0                13000  dp0_server1   gpu1              3             3          HBM     peerGPU  dp0_server1     gpu1  dp0_server1     gpu2  1.379915e-06  6.666667e-10  3.576279e-06
4            104            4                maxpool                                (relu,)   576000    144000        0         0         0         0    call_module                  maxpool    MaxPool2d  torch.Size([32, 64, 112, 112])    torch.Size([32, 64, 56, 56])                         None                                 {'kernel_size': 3, 'stride': 2, 'padding': 1, 'dilation': 1, 'ceil_mode': False}           4       FWD                1                 0                0                 0                         0                14000  dp0_server1   gpu2              4             0      peerGPU         HBM  dp0_server1     gpu1  dp0_server1     gpu2  3.576279e-06  7.179487e-10  3.449787e-07
5            105            5         layer1_0_conv1                             (maxpool,)   144000    144000     4096         0         0         0    call_module           layer1.0.conv1       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                1                 0                0                 0                         0                15000  dp0_server1   gpu2              5             1          HBM         HBM  dp0_server1     gpu2  dp0_server1     gpu2  3.449787e-07  7.692308e-10  3.449787e-07
6            106            6           layer1_0_bn1                      (layer1_0_conv1,)   144000    144000      128         0         0         0    call_module             layer1.0.bn1  BatchNorm2d   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                1                 0                0                 0                         0                16000  dp0_server1   gpu2              6             2          HBM         HBM  dp0_server1     gpu2  dp0_server1     gpu2  3.449787e-07  8.205128e-10  3.449787e-07
7            107            7          layer1_0_relu                        (layer1_0_bn1,)   144000    144000        0         0         0         0    call_module            layer1.0.relu         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                1                 0                0                 0                         0                17000  dp0_server1   gpu2              7             3          HBM     peerGPU  dp0_server1     gpu2  dp0_server1     gpu3  3.449787e-07  8.717949e-10  8.940697e-07
8            108            8         layer1_0_conv2                       (layer1_0_relu,)   144000    144000    36864         0         0         0    call_module           layer1.0.conv2       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 3, 3])  {'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                2                 0                0                 0                         0                18000  dp0_server1   gpu3              8             0      peerGPU         HBM  dp0_server1     gpu2  dp0_server1     gpu3  8.940697e-07  9.230769e-10  3.449787e-07
9            109            9           layer1_0_bn2                      (layer1_0_conv2,)   144000    144000      128         0         0         0    call_module             layer1.0.bn2  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                2                 0                0                 0                         0                19000  dp0_server1   gpu3              9             1          HBM         HBM  dp0_server1     gpu3  dp0_server1     gpu3  3.449787e-07  9.743590e-10  3.449787e-07
10           110           10        layer1_0_relu_1                        (layer1_0_bn2,)   144000    144000        0         0         0         0    call_module          layer1.0.relu_1         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                2                 0                0                 0                         0                20000  dp0_server1   gpu3             10             2          HBM         HBM  dp0_server1     gpu3  dp0_server1     gpu3  3.449787e-07  1.025641e-09  3.449787e-07
11           111           11         layer1_0_conv3                     (layer1_0_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.0.conv3       Conv2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                2                 0                0                 0                         0                21000  dp0_server1   gpu3             11             3          HBM     peerGPU  dp0_server1     gpu3  dp0_server1     gpu4  3.449787e-07  1.076923e-09  3.576279e-06
12           112           12           layer1_0_bn3                      (layer1_0_conv3,)   576000    576000      512         0         0         0    call_module             layer1.0.bn3  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                3                 0                0                 0                         0                22000  dp0_server1   gpu4             12             0      peerGPU         HBM  dp0_server1     gpu3  dp0_server1     gpu4  3.576279e-06  1.128205e-09  1.379915e-06
13           113           13  layer1_0_downsample_0               (layer1_0_downsample_0,)   576000    576000    16384         0         0         0    call_module    layer1.0.downsample.0       Conv2d    torch.Size([32, 64, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (2, 2), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                3                 0                0                 0                         0                23000  dp0_server1   gpu4             13             1          HBM     network  dp0_server1     gpu4  dp0_server2     gpu1  1.379915e-06  1.179487e-09  3.352761e-05
14           114           14  layer1_0_downsample_1               (layer1_0_downsample_1,)   576000    576000      512         0         0         0    call_module    layer1.0.downsample.1  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                4                 0                0                 0                         0                24000  dp0_server2   gpu1              0             0      network         HBM  dp0_server1     gpu4  dp0_server2     gpu1  3.352761e-05  1.230769e-09  1.379915e-06
15           115           15                    add  (layer1_0_bn3, layer1_0_downsample_1)   576000    576000        0         0         0         0  call_function  <built-in function add>       Tensor   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                             None           4       FWD                4                 0                0                 0                         0                25000  dp0_server2   gpu1              1             1          HBM         HBM  dp0_server2     gpu1  dp0_server2     gpu1  1.379915e-06  1.282051e-09  1.379915e-06
16           116           16        layer1_0_relu_2                                 (add,)   576000    576000        0         0         0         0    call_module            layer1.0.relu         ReLU   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                4                 0                0                 0                         0                26000  dp0_server2   gpu1              2             2          HBM     peerGPU  dp0_server2     gpu1  dp0_server2     gpu2  1.379915e-06  1.333333e-09  3.576279e-06
17           117           17         layer1_1_conv1                     (layer1_0_relu_2,)   144000    144000    16384         0         0         0    call_module           layer1.1.conv1       Conv2d   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                5                 0                0                 0                         0                27000  dp0_server2   gpu2              3             0      peerGPU         HBM  dp0_server2     gpu1  dp0_server2     gpu2  8.940697e-07  1.384615e-09  3.449787e-07
18           118           18           layer1_1_bn1                      (layer1_1_conv1,)   144000    144000      128         0         0         0    call_module             layer1.1.bn1  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                5                 0                0                 0                         0                28000  dp0_server2   gpu2              4             1          HBM     peerGPU  dp0_server2     gpu2  dp0_server2     gpu3  3.449787e-07  1.435897e-09  8.940697e-07
19           119           19          layer1_1_relu                        (layer1_1_bn1,)   144000    144000        0         0         0         0    call_module            layer1.1.relu         ReLU   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                6                 0                0                 0                         0                29000  dp0_server2   gpu3              5             0      peerGPU         HBM  dp0_server2     gpu2  dp0_server2     gpu3  8.940697e-07  1.487179e-09  3.449787e-07
20           120           20         layer1_1_conv2                       (layer1_1_relu,)   144000    144000    36864         0         0         0    call_module           layer1.1.conv2       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 3, 3])  {'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                6                 0                0                 0                         0                30000  dp0_server2   gpu3              6             1          HBM         HBM  dp0_server2     gpu3  dp0_server2     gpu3  3.449787e-07  1.538462e-09  3.449787e-07
21           121           21           layer1_1_bn2                      (layer1_1_conv2,)   144000    144000      128         0         0         0    call_module             layer1.1.bn2  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                6                 0                0                 0                         0                31000  dp0_server2   gpu3              7             2          HBM     peerGPU  dp0_server2     gpu3  dp0_server2     gpu4  3.449787e-07  1.589744e-09  8.940697e-07
22           122           22        layer1_1_relu_1                        (layer1_1_bn2,)   144000    144000        0         0         0         0    call_module          layer1.1.relu_1         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                7                 0                0                 0                         0                32000  dp0_server2   gpu4              8             0      peerGPU         HBM  dp0_server2     gpu3  dp0_server2     gpu4  8.940697e-07  1.641026e-09  3.449787e-07
23           123           23         layer1_1_conv3                     (layer1_1_relu_1,)   576000    576000    16384         0         0         0    call_module           layer1.1.conv3       Conv2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                7                 0                0                 0                         0                33000  dp0_server2   gpu4              9             1          HBM         HBM  dp0_server2     gpu4  dp0_server2     gpu4  1.379915e-06  1.692308e-09  1.379915e-06
24           124           24           layer1_1_bn3                      (layer1_1_conv3,)   576000    576000      512         0         0         0    call_module             layer1.1.bn3  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                7                 0                0                 0                         0                34000  dp0_server2   gpu4             10             2          HBM         HBM  dp0_server2     gpu4  dp0_server2     gpu4  1.379915e-06  1.743590e-09  1.379915e-06
25           125           25                  add_1                        (layer1_1_bn3,)   576000    576000        0         0         0         0  call_function  <built-in function add>       Tensor   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                             None           4       FWD                7                 0                0                 0                         0                35000  dp0_server2   gpu4             11             3          HBM         HBM  dp0_server2     gpu4         None     None  1.379915e-06  1.794872e-09  1.379915e-06

Loading layer x to dp1_server1[0], gpu1[0]
Loading layer conv1 to dp1_server1[1], gpu1[1]
Loading layer bn1 to dp1_server1[2], gpu1[2]
Loading layer relu to dp1_server1[3], gpu1[3]
Loading layer maxpool to dp1_server1[4], gpu2[0]
Loading layer layer1_0_conv1 to dp1_server1[5], gpu2[1]
Loading layer layer1_0_bn1 to dp1_server1[6], gpu2[2]
Loading layer layer1_0_relu to dp1_server1[7], gpu2[3]
Loading layer layer1_0_conv2 to dp1_server1[8], gpu3[0]
Loading layer layer1_0_bn2 to dp1_server1[9], gpu3[1]
Loading layer layer1_0_relu_1 to dp1_server1[10], gpu3[2]
Loading layer layer1_0_conv3 to dp1_server1[11], gpu3[3]
Loading layer layer1_0_bn3 to dp1_server1[12], gpu4[0]
Loading layer layer1_0_downsample_0 to dp1_server1[13], gpu4[1]
Loading layer layer1_0_downsample_1 to dp1_server2[0], gpu1[0]
Loading layer add to dp1_server2[1], gpu1[1]
Loading layer layer1_0_relu_2 to dp1_server2[2], gpu1[2]
Loading layer layer1_1_conv1 to dp1_server2[3], gpu2[0]
Loading layer layer1_1_bn1 to dp1_server2[4], gpu2[1]
Loading layer layer1_1_relu to dp1_server2[5], gpu3[0]
Loading layer layer1_1_conv2 to dp1_server2[6], gpu3[1]
Loading layer layer1_1_bn2 to dp1_server2[7], gpu3[2]
Loading layer layer1_1_relu_1 to dp1_server2[8], gpu4[0]
Loading layer layer1_1_conv3 to dp1_server2[9], gpu4[1]
Loading layer layer1_1_bn3 to dp1_server2[10], gpu4[2]
Loading layer add_1 to dp1_server2[11], gpu4[3]
    global_index  layer_index                   name                                   args  input_#  output_#  Param_#  dp_index  pp_index  tp_index         opcode                   target   layer_type                     input_shape                    output_shape                  param_shape                                                                                                           kwargs  dtype_size direction  avg_mem_grp_idx  avg_mem_grp_size  min_comm_grp_id  min_comm_grp_sum  min_comm_grp_last_weight  compute_density_ops    server_id gpu_id  index_on_host  index_on_GPU input_source output_dest  prev_server prev_gpu  next_server next_gpu     read_time     exec_time    write_time
0            100            0                      x                                     ()      100       100        0         0         0         0    placeholder                        x         None   torch.Size([32, 3, 224, 224])  torch.Size([32, 64, 112, 112])                         None                                                                                                             None           4       FWD                0                 0                0                 0                         0                10000  dp1_server1   gpu1              0             0         host         HBM         None     None  dp1_server1     gpu1  5.820766e-09  5.128205e-10  2.395685e-10
1            101            1                  conv1                                   (x,)     7840    576000      576         0         0         0    call_module                    conv1       Conv2d  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])    torch.Size([64, 3, 7, 7])                                                             {'stride': (2, 2), 'padding': (3, 3), 'bias': False}           4       FWD                0                 0                0                 0                         0                11000  dp1_server1   gpu1              1             1          HBM         HBM  dp1_server1     gpu1  dp1_server1     gpu1  1.878217e-08  5.641026e-10  1.379915e-06
2            102            2                    bn1                               (conv1,)   576000    576000      128         0         0         0    call_module                      bn1  BatchNorm2d  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                0                 0                0                 0                         0                12000  dp1_server1   gpu1              2             2          HBM         HBM  dp1_server1     gpu1  dp1_server1     gpu1  1.379915e-06  6.153846e-10  1.379915e-06
3            103            3                   relu                                 (bn1,)   576000    576000        0         0         0         0    call_module                     relu         ReLU  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])                         None                                                                                                {'inplace': True}           4       FWD                0                 0                0                 0                         0                13000  dp1_server1   gpu1              3             3          HBM     peerGPU  dp1_server1     gpu1  dp1_server1     gpu2  1.379915e-06  6.666667e-10  3.576279e-06
4            104            4                maxpool                                (relu,)   576000    144000        0         0         0         0    call_module                  maxpool    MaxPool2d  torch.Size([32, 64, 112, 112])    torch.Size([32, 64, 56, 56])                         None                                 {'kernel_size': 3, 'stride': 2, 'padding': 1, 'dilation': 1, 'ceil_mode': False}           4       FWD                1                 0                0                 0                         0                14000  dp1_server1   gpu2              4             0      peerGPU         HBM  dp1_server1     gpu1  dp1_server1     gpu2  3.576279e-06  7.179487e-10  3.449787e-07
5            105            5         layer1_0_conv1                             (maxpool,)   144000    144000     4096         0         0         0    call_module           layer1.0.conv1       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                1                 0                0                 0                         0                15000  dp1_server1   gpu2              5             1          HBM         HBM  dp1_server1     gpu2  dp1_server1     gpu2  3.449787e-07  7.692308e-10  3.449787e-07
6            106            6           layer1_0_bn1                      (layer1_0_conv1,)   144000    144000      128         0         0         0    call_module             layer1.0.bn1  BatchNorm2d   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                1                 0                0                 0                         0                16000  dp1_server1   gpu2              6             2          HBM         HBM  dp1_server1     gpu2  dp1_server1     gpu2  3.449787e-07  8.205128e-10  3.449787e-07
7            107            7          layer1_0_relu                        (layer1_0_bn1,)   144000    144000        0         0         0         0    call_module            layer1.0.relu         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                1                 0                0                 0                         0                17000  dp1_server1   gpu2              7             3          HBM     peerGPU  dp1_server1     gpu2  dp1_server1     gpu3  3.449787e-07  8.717949e-10  8.940697e-07
8            108            8         layer1_0_conv2                       (layer1_0_relu,)   144000    144000    36864         0         0         0    call_module           layer1.0.conv2       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 3, 3])  {'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                2                 0                0                 0                         0                18000  dp1_server1   gpu3              8             0      peerGPU         HBM  dp1_server1     gpu2  dp1_server1     gpu3  8.940697e-07  9.230769e-10  3.449787e-07
9            109            9           layer1_0_bn2                      (layer1_0_conv2,)   144000    144000      128         0         0         0    call_module             layer1.0.bn2  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                2                 0                0                 0                         0                19000  dp1_server1   gpu3              9             1          HBM         HBM  dp1_server1     gpu3  dp1_server1     gpu3  3.449787e-07  9.743590e-10  3.449787e-07
10           110           10        layer1_0_relu_1                        (layer1_0_bn2,)   144000    144000        0         0         0         0    call_module          layer1.0.relu_1         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                2                 0                0                 0                         0                20000  dp1_server1   gpu3             10             2          HBM         HBM  dp1_server1     gpu3  dp1_server1     gpu3  3.449787e-07  1.025641e-09  3.449787e-07
11           111           11         layer1_0_conv3                     (layer1_0_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.0.conv3       Conv2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                2                 0                0                 0                         0                21000  dp1_server1   gpu3             11             3          HBM     peerGPU  dp1_server1     gpu3  dp1_server1     gpu4  3.449787e-07  1.076923e-09  3.576279e-06
12           112           12           layer1_0_bn3                      (layer1_0_conv3,)   576000    576000      512         0         0         0    call_module             layer1.0.bn3  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                3                 0                0                 0                         0                22000  dp1_server1   gpu4             12             0      peerGPU         HBM  dp1_server1     gpu3  dp1_server1     gpu4  3.576279e-06  1.128205e-09  1.379915e-06
13           113           13  layer1_0_downsample_0               (layer1_0_downsample_0,)   576000    576000    16384         0         0         0    call_module    layer1.0.downsample.0       Conv2d    torch.Size([32, 64, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (2, 2), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                3                 0                0                 0                         0                23000  dp1_server1   gpu4             13             1          HBM     network  dp1_server1     gpu4  dp1_server2     gpu1  1.379915e-06  1.179487e-09  3.352761e-05
14           114           14  layer1_0_downsample_1               (layer1_0_downsample_1,)   576000    576000      512         0         0         0    call_module    layer1.0.downsample.1  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                4                 0                0                 0                         0                24000  dp1_server2   gpu1              0             0      network         HBM  dp1_server1     gpu4  dp1_server2     gpu1  3.352761e-05  1.230769e-09  1.379915e-06
15           115           15                    add  (layer1_0_bn3, layer1_0_downsample_1)   576000    576000        0         0         0         0  call_function  <built-in function add>       Tensor   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                             None           4       FWD                4                 0                0                 0                         0                25000  dp1_server2   gpu1              1             1          HBM         HBM  dp1_server2     gpu1  dp1_server2     gpu1  1.379915e-06  1.282051e-09  1.379915e-06
16           116           16        layer1_0_relu_2                                 (add,)   576000    576000        0         0         0         0    call_module            layer1.0.relu         ReLU   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                4                 0                0                 0                         0                26000  dp1_server2   gpu1              2             2          HBM     peerGPU  dp1_server2     gpu1  dp1_server2     gpu2  1.379915e-06  1.333333e-09  3.576279e-06
17           117           17         layer1_1_conv1                     (layer1_0_relu_2,)   144000    144000    16384         0         0         0    call_module           layer1.1.conv1       Conv2d   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                5                 0                0                 0                         0                27000  dp1_server2   gpu2              3             0      peerGPU         HBM  dp1_server2     gpu1  dp1_server2     gpu2  8.940697e-07  1.384615e-09  3.449787e-07
18           118           18           layer1_1_bn1                      (layer1_1_conv1,)   144000    144000      128         0         0         0    call_module             layer1.1.bn1  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                5                 0                0                 0                         0                28000  dp1_server2   gpu2              4             1          HBM     peerGPU  dp1_server2     gpu2  dp1_server2     gpu3  3.449787e-07  1.435897e-09  8.940697e-07
19           119           19          layer1_1_relu                        (layer1_1_bn1,)   144000    144000        0         0         0         0    call_module            layer1.1.relu         ReLU   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                6                 0                0                 0                         0                29000  dp1_server2   gpu3              5             0      peerGPU         HBM  dp1_server2     gpu2  dp1_server2     gpu3  8.940697e-07  1.487179e-09  3.449787e-07
20           120           20         layer1_1_conv2                       (layer1_1_relu,)   144000    144000    36864         0         0         0    call_module           layer1.1.conv2       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 3, 3])  {'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                6                 0                0                 0                         0                30000  dp1_server2   gpu3              6             1          HBM         HBM  dp1_server2     gpu3  dp1_server2     gpu3  3.449787e-07  1.538462e-09  3.449787e-07
21           121           21           layer1_1_bn2                      (layer1_1_conv2,)   144000    144000      128         0         0         0    call_module             layer1.1.bn2  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                6                 0                0                 0                         0                31000  dp1_server2   gpu3              7             2          HBM     peerGPU  dp1_server2     gpu3  dp1_server2     gpu4  3.449787e-07  1.589744e-09  8.940697e-07
22           122           22        layer1_1_relu_1                        (layer1_1_bn2,)   144000    144000        0         0         0         0    call_module          layer1.1.relu_1         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                7                 0                0                 0                         0                32000  dp1_server2   gpu4              8             0      peerGPU         HBM  dp1_server2     gpu3  dp1_server2     gpu4  8.940697e-07  1.641026e-09  3.449787e-07
23           123           23         layer1_1_conv3                     (layer1_1_relu_1,)   576000    576000    16384         0         0         0    call_module           layer1.1.conv3       Conv2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                7                 0                0                 0                         0                33000  dp1_server2   gpu4              9             1          HBM         HBM  dp1_server2     gpu4  dp1_server2     gpu4  1.379915e-06  1.692308e-09  1.379915e-06
24           124           24           layer1_1_bn3                      (layer1_1_conv3,)   576000    576000      512         0         0         0    call_module             layer1.1.bn3  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                7                 0                0                 0                         0                34000  dp1_server2   gpu4             10             2          HBM         HBM  dp1_server2     gpu4  dp1_server2     gpu4  1.379915e-06  1.743590e-09  1.379915e-06
25           125           25                  add_1                        (layer1_1_bn3,)   576000    576000        0         0         0         0  call_function  <built-in function add>       Tensor   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                             None           4       FWD                7                 0                0                 0                         0                35000  dp1_server2   gpu4             11             3          HBM         HBM  dp1_server2     gpu4         None     None  1.379915e-06  1.794872e-09  1.379915e-06

DP group 0
{'server_id': 'dp0_server1', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7f43b985f190>), ('gpu2', <__main__.GPU object at 0x7f43b985f280>), ('gpu3', <__main__.GPU object at 0x7f43b985f370>), ('gpu4', <__main__.GPU object at 0x7f43b985f460>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7f43b985f4c0>), ('net2', <__main__.NetworkCard object at 0x7f43b985f550>), ('net3', <__main__.NetworkCard object at 0x7f43b985f5e0>), ('net4', <__main__.NetworkCard object at 0x7f43b985f670>)]), 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871730>), (1, <__main__.Layer object at 0x7f43b98716d0>), (2, <__main__.Layer object at 0x7f43b9871880>), (3, <__main__.Layer object at 0x7f43b9871850>), (4, <__main__.Layer object at 0x7f43b98715e0>), (5, <__main__.Layer object at 0x7f43b98717f0>), (6, <__main__.Layer object at 0x7f43b9871790>), (7, <__main__.Layer object at 0x7f43b9871760>), (8, <__main__.Layer object at 0x7f43b98718e0>), (9, <__main__.Layer object at 0x7f43b98719a0>), (10, <__main__.Layer object at 0x7f43b98719d0>), (11, <__main__.Layer object at 0x7f43b9871a00>), (12, <__main__.Layer object at 0x7f43b9871a30>), (13, <__main__.Layer object at 0x7f43b9871a60>)]), 'min_layer_index': 0, 'max_layer_index': 13}
{'server': <__main__.Server object at 0x7f43bc962f40>, 'gpu_id': 'gpu1', 'server_id': 'dp0_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871730>), (1, <__main__.Layer object at 0x7f43b98716d0>), (2, <__main__.Layer object at 0x7f43b9871880>), (3, <__main__.Layer object at 0x7f43b9871850>)]), 'model_size': 2816, 'min_layer_index': 0, 'max_layer_index': 3}
{'server': <__main__.Server object at 0x7f43bc962f40>, 'gpu_id': 'gpu2', 'server_id': 'dp0_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b98715e0>), (1, <__main__.Layer object at 0x7f43b98717f0>), (2, <__main__.Layer object at 0x7f43b9871790>), (3, <__main__.Layer object at 0x7f43b9871760>)]), 'model_size': 16896, 'min_layer_index': 4, 'max_layer_index': 7}
{'server': <__main__.Server object at 0x7f43bc962f40>, 'gpu_id': 'gpu3', 'server_id': 'dp0_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b98718e0>), (1, <__main__.Layer object at 0x7f43b98719a0>), (2, <__main__.Layer object at 0x7f43b98719d0>), (3, <__main__.Layer object at 0x7f43b9871a00>)]), 'model_size': 213504, 'min_layer_index': 8, 'max_layer_index': 11}
{'server': <__main__.Server object at 0x7f43bc962f40>, 'gpu_id': 'gpu4', 'server_id': 'dp0_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871a30>), (1, <__main__.Layer object at 0x7f43b9871a60>)]), 'model_size': 67584, 'min_layer_index': 12, 'max_layer_index': 13}
{'server': <__main__.Server object at 0x7f43bc962f40>, 'network_card_id': 'net1', 'server_id': 'dp0_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43bc962f40>, 'network_card_id': 'net2', 'server_id': 'dp0_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43bc962f40>, 'network_card_id': 'net3', 'server_id': 'dp0_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43bc962f40>, 'network_card_id': 'net4', 'server_id': 'dp0_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp0_server2', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7f43b985f7f0>), ('gpu2', <__main__.GPU object at 0x7f43b985f8e0>), ('gpu3', <__main__.GPU object at 0x7f43b985f9d0>), ('gpu4', <__main__.GPU object at 0x7f43b985fac0>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7f43b985fb20>), ('net2', <__main__.NetworkCard object at 0x7f43b985fbb0>), ('net3', <__main__.NetworkCard object at 0x7f43b985fc40>), ('net4', <__main__.NetworkCard object at 0x7f43b985fcd0>)]), 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871a90>), (1, <__main__.Layer object at 0x7f43b9871ac0>), (2, <__main__.Layer object at 0x7f43b9871af0>), (3, <__main__.Layer object at 0x7f43b9871b20>), (4, <__main__.Layer object at 0x7f43b9871b50>), (5, <__main__.Layer object at 0x7f43b9871b80>), (6, <__main__.Layer object at 0x7f43b9871bb0>), (7, <__main__.Layer object at 0x7f43b9871be0>), (8, <__main__.Layer object at 0x7f43b9871c10>), (9, <__main__.Layer object at 0x7f43b9871c40>), (10, <__main__.Layer object at 0x7f43b9871c70>), (11, <__main__.Layer object at 0x7f43b9871ca0>)]), 'min_layer_index': 14, 'max_layer_index': 25}
{'server': <__main__.Server object at 0x7f43b985f490>, 'gpu_id': 'gpu1', 'server_id': 'dp0_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871a90>), (1, <__main__.Layer object at 0x7f43b9871ac0>), (2, <__main__.Layer object at 0x7f43b9871af0>)]), 'model_size': 2048, 'min_layer_index': 14, 'max_layer_index': 16}
{'server': <__main__.Server object at 0x7f43b985f490>, 'gpu_id': 'gpu2', 'server_id': 'dp0_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871b20>), (1, <__main__.Layer object at 0x7f43b9871b50>)]), 'model_size': 66048, 'min_layer_index': 17, 'max_layer_index': 18}
{'server': <__main__.Server object at 0x7f43b985f490>, 'gpu_id': 'gpu3', 'server_id': 'dp0_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871b80>), (1, <__main__.Layer object at 0x7f43b9871bb0>), (2, <__main__.Layer object at 0x7f43b9871be0>)]), 'model_size': 147968, 'min_layer_index': 19, 'max_layer_index': 21}
{'server': <__main__.Server object at 0x7f43b985f490>, 'gpu_id': 'gpu4', 'server_id': 'dp0_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871c10>), (1, <__main__.Layer object at 0x7f43b9871c40>), (2, <__main__.Layer object at 0x7f43b9871c70>), (3, <__main__.Layer object at 0x7f43b9871ca0>)]), 'model_size': 67584, 'min_layer_index': 22, 'max_layer_index': 25}
{'server': <__main__.Server object at 0x7f43b985f490>, 'network_card_id': 'net1', 'server_id': 'dp0_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b985f490>, 'network_card_id': 'net2', 'server_id': 'dp0_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b985f490>, 'network_card_id': 'net3', 'server_id': 'dp0_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b985f490>, 'network_card_id': 'net4', 'server_id': 'dp0_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp0_server3', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7f43b985fe50>), ('gpu2', <__main__.GPU object at 0x7f43b985ff40>), ('gpu3', <__main__.GPU object at 0x7f43b9869070>), ('gpu4', <__main__.GPU object at 0x7f43b9869160>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7f43b98691c0>), ('net2', <__main__.NetworkCard object at 0x7f43b9869250>), ('net3', <__main__.NetworkCard object at 0x7f43b98692e0>), ('net4', <__main__.NetworkCard object at 0x7f43b9869370>)]), 'model_layers': OrderedDict(), 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b985faf0>, 'gpu_id': 'gpu1', 'server_id': 'dp0_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b985faf0>, 'gpu_id': 'gpu2', 'server_id': 'dp0_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b985faf0>, 'gpu_id': 'gpu3', 'server_id': 'dp0_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b985faf0>, 'gpu_id': 'gpu4', 'server_id': 'dp0_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b985faf0>, 'network_card_id': 'net1', 'server_id': 'dp0_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b985faf0>, 'network_card_id': 'net2', 'server_id': 'dp0_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b985faf0>, 'network_card_id': 'net3', 'server_id': 'dp0_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b985faf0>, 'network_card_id': 'net4', 'server_id': 'dp0_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp0_server4', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7f43b98694f0>), ('gpu2', <__main__.GPU object at 0x7f43b98695e0>), ('gpu3', <__main__.GPU object at 0x7f43b98696d0>), ('gpu4', <__main__.GPU object at 0x7f43b98697c0>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7f43b9869820>), ('net2', <__main__.NetworkCard object at 0x7f43b98698b0>), ('net3', <__main__.NetworkCard object at 0x7f43b9869940>), ('net4', <__main__.NetworkCard object at 0x7f43b98699d0>)]), 'model_layers': OrderedDict(), 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b9869190>, 'gpu_id': 'gpu1', 'server_id': 'dp0_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b9869190>, 'gpu_id': 'gpu2', 'server_id': 'dp0_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b9869190>, 'gpu_id': 'gpu3', 'server_id': 'dp0_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b9869190>, 'gpu_id': 'gpu4', 'server_id': 'dp0_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b9869190>, 'network_card_id': 'net1', 'server_id': 'dp0_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b9869190>, 'network_card_id': 'net2', 'server_id': 'dp0_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b9869190>, 'network_card_id': 'net3', 'server_id': 'dp0_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b9869190>, 'network_card_id': 'net4', 'server_id': 'dp0_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
DP group 1
{'server_id': 'dp1_server1', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7f43b9869b50>), ('gpu2', <__main__.GPU object at 0x7f43b9869c40>), ('gpu3', <__main__.GPU object at 0x7f43b9869d30>), ('gpu4', <__main__.GPU object at 0x7f43b9869e20>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7f43b9869e80>), ('net2', <__main__.NetworkCard object at 0x7f43b9869f10>), ('net3', <__main__.NetworkCard object at 0x7f43b9869fa0>), ('net4', <__main__.NetworkCard object at 0x7f43b986c070>)]), 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871d00>), (1, <__main__.Layer object at 0x7f43b9871df0>), (2, <__main__.Layer object at 0x7f43b9871dc0>), (3, <__main__.Layer object at 0x7f43b98711f0>), (4, <__main__.Layer object at 0x7f43b9871e20>), (5, <__main__.Layer object at 0x7f43b98718b0>), (6, <__main__.Layer object at 0x7f43b9871700>), (7, <__main__.Layer object at 0x7f43b9871610>), (8, <__main__.Layer object at 0x7f43b9871e50>), (9, <__main__.Layer object at 0x7f43b9871e80>), (10, <__main__.Layer object at 0x7f43b9871eb0>), (11, <__main__.Layer object at 0x7f43b9871ee0>), (12, <__main__.Layer object at 0x7f43b9871f10>), (13, <__main__.Layer object at 0x7f43b9871f40>)]), 'min_layer_index': 0, 'max_layer_index': 13}
{'server': <__main__.Server object at 0x7f43bc83e4c0>, 'gpu_id': 'gpu1', 'server_id': 'dp1_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871d00>), (1, <__main__.Layer object at 0x7f43b9871df0>), (2, <__main__.Layer object at 0x7f43b9871dc0>), (3, <__main__.Layer object at 0x7f43b98711f0>)]), 'model_size': 2816, 'min_layer_index': 0, 'max_layer_index': 3}
{'server': <__main__.Server object at 0x7f43bc83e4c0>, 'gpu_id': 'gpu2', 'server_id': 'dp1_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871e20>), (1, <__main__.Layer object at 0x7f43b98718b0>), (2, <__main__.Layer object at 0x7f43b9871700>), (3, <__main__.Layer object at 0x7f43b9871610>)]), 'model_size': 16896, 'min_layer_index': 4, 'max_layer_index': 7}
{'server': <__main__.Server object at 0x7f43bc83e4c0>, 'gpu_id': 'gpu3', 'server_id': 'dp1_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871e50>), (1, <__main__.Layer object at 0x7f43b9871e80>), (2, <__main__.Layer object at 0x7f43b9871eb0>), (3, <__main__.Layer object at 0x7f43b9871ee0>)]), 'model_size': 213504, 'min_layer_index': 8, 'max_layer_index': 11}
{'server': <__main__.Server object at 0x7f43bc83e4c0>, 'gpu_id': 'gpu4', 'server_id': 'dp1_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871f10>), (1, <__main__.Layer object at 0x7f43b9871f40>)]), 'model_size': 67584, 'min_layer_index': 12, 'max_layer_index': 13}
{'server': <__main__.Server object at 0x7f43bc83e4c0>, 'network_card_id': 'net1', 'server_id': 'dp1_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43bc83e4c0>, 'network_card_id': 'net2', 'server_id': 'dp1_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43bc83e4c0>, 'network_card_id': 'net3', 'server_id': 'dp1_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43bc83e4c0>, 'network_card_id': 'net4', 'server_id': 'dp1_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp1_server2', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7f43b986c1f0>), ('gpu2', <__main__.GPU object at 0x7f43b986c2e0>), ('gpu3', <__main__.GPU object at 0x7f43b986c3d0>), ('gpu4', <__main__.GPU object at 0x7f43b986c4c0>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7f43b986c520>), ('net2', <__main__.NetworkCard object at 0x7f43b986c5b0>), ('net3', <__main__.NetworkCard object at 0x7f43b986c640>), ('net4', <__main__.NetworkCard object at 0x7f43b986c6d0>)]), 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871d60>), (1, <__main__.Layer object at 0x7f43b9871d90>), (2, <__main__.Layer object at 0x7f43b9871fd0>), (3, <__main__.Layer object at 0x7f43b9871940>), (4, <__main__.Layer object at 0x7f43b9871820>), (5, <__main__.Layer object at 0x7f43b9871fa0>), (6, <__main__.Layer object at 0x7f43b98070d0>), (7, <__main__.Layer object at 0x7f43b9807100>), (8, <__main__.Layer object at 0x7f43b9807130>), (9, <__main__.Layer object at 0x7f43b9807040>), (10, <__main__.Layer object at 0x7f43b98071c0>), (11, <__main__.Layer object at 0x7f43b98071f0>)]), 'min_layer_index': 14, 'max_layer_index': 25}
{'server': <__main__.Server object at 0x7f43b9869e50>, 'gpu_id': 'gpu1', 'server_id': 'dp1_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871d60>), (1, <__main__.Layer object at 0x7f43b9871d90>), (2, <__main__.Layer object at 0x7f43b9871fd0>)]), 'model_size': 2048, 'min_layer_index': 14, 'max_layer_index': 16}
{'server': <__main__.Server object at 0x7f43b9869e50>, 'gpu_id': 'gpu2', 'server_id': 'dp1_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871940>), (1, <__main__.Layer object at 0x7f43b9871820>)]), 'model_size': 66048, 'min_layer_index': 17, 'max_layer_index': 18}
{'server': <__main__.Server object at 0x7f43b9869e50>, 'gpu_id': 'gpu3', 'server_id': 'dp1_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9871fa0>), (1, <__main__.Layer object at 0x7f43b98070d0>), (2, <__main__.Layer object at 0x7f43b9807100>)]), 'model_size': 147968, 'min_layer_index': 19, 'max_layer_index': 21}
{'server': <__main__.Server object at 0x7f43b9869e50>, 'gpu_id': 'gpu4', 'server_id': 'dp1_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7f43b9807130>), (1, <__main__.Layer object at 0x7f43b9807040>), (2, <__main__.Layer object at 0x7f43b98071c0>), (3, <__main__.Layer object at 0x7f43b98071f0>)]), 'model_size': 67584, 'min_layer_index': 22, 'max_layer_index': 25}
{'server': <__main__.Server object at 0x7f43b9869e50>, 'network_card_id': 'net1', 'server_id': 'dp1_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b9869e50>, 'network_card_id': 'net2', 'server_id': 'dp1_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b9869e50>, 'network_card_id': 'net3', 'server_id': 'dp1_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b9869e50>, 'network_card_id': 'net4', 'server_id': 'dp1_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp1_server3', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7f43b986c850>), ('gpu2', <__main__.GPU object at 0x7f43b986c940>), ('gpu3', <__main__.GPU object at 0x7f43b986ca30>), ('gpu4', <__main__.GPU object at 0x7f43b986cb20>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7f43b986cb80>), ('net2', <__main__.NetworkCard object at 0x7f43b986cc10>), ('net3', <__main__.NetworkCard object at 0x7f43b986cca0>), ('net4', <__main__.NetworkCard object at 0x7f43b986cd30>)]), 'model_layers': OrderedDict(), 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986c4f0>, 'gpu_id': 'gpu1', 'server_id': 'dp1_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986c4f0>, 'gpu_id': 'gpu2', 'server_id': 'dp1_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986c4f0>, 'gpu_id': 'gpu3', 'server_id': 'dp1_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986c4f0>, 'gpu_id': 'gpu4', 'server_id': 'dp1_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986c4f0>, 'network_card_id': 'net1', 'server_id': 'dp1_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b986c4f0>, 'network_card_id': 'net2', 'server_id': 'dp1_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b986c4f0>, 'network_card_id': 'net3', 'server_id': 'dp1_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b986c4f0>, 'network_card_id': 'net4', 'server_id': 'dp1_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp1_server4', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7f43b986ceb0>), ('gpu2', <__main__.GPU object at 0x7f43b986cfa0>), ('gpu3', <__main__.GPU object at 0x7f43b98710d0>), ('gpu4', <__main__.GPU object at 0x7f43b98711c0>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7f43b9871220>), ('net2', <__main__.NetworkCard object at 0x7f43b98712b0>), ('net3', <__main__.NetworkCard object at 0x7f43b9871340>), ('net4', <__main__.NetworkCard object at 0x7f43b98713d0>)]), 'model_layers': OrderedDict(), 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986cb50>, 'gpu_id': 'gpu1', 'server_id': 'dp1_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986cb50>, 'gpu_id': 'gpu2', 'server_id': 'dp1_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986cb50>, 'gpu_id': 'gpu3', 'server_id': 'dp1_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986cb50>, 'gpu_id': 'gpu4', 'server_id': 'dp1_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7f43b986cb50>, 'network_card_id': 'net1', 'server_id': 'dp1_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b986cb50>, 'network_card_id': 'net2', 'server_id': 'dp1_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b986cb50>, 'network_card_id': 'net3', 'server_id': 'dp1_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7f43b986cb50>, 'network_card_id': 'net4', 'server_id': 'dp1_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}

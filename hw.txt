Loading layer x to dp0_server1[0], gpu1[0]
Loading layer conv1 to dp0_server1[1], gpu1[1]
Loading layer bn1 to dp0_server1[2], gpu1[2]
Loading layer relu to dp0_server1[3], gpu1[3]
Loading layer maxpool to dp0_server1[4], gpu2[0]
Loading layer layer1_0_conv1 to dp0_server1[5], gpu2[1]
Loading layer layer1_0_bn1 to dp0_server1[6], gpu2[2]
Loading layer layer1_0_relu to dp0_server1[7], gpu2[3]
Loading layer layer1_0_conv2 to dp0_server1[8], gpu3[0]
Loading layer layer1_0_bn2 to dp0_server1[9], gpu3[1]
Loading layer layer1_0_relu_1 to dp0_server1[10], gpu3[2]
Loading layer layer1_0_conv3 to dp0_server1[11], gpu3[3]
Loading layer layer1_0_bn3 to dp0_server1[12], gpu4[0]
Loading layer layer1_0_downsample_0 to dp0_server1[13], gpu4[1]
Loading layer layer1_0_downsample_1 to dp0_server2[0], gpu1[0]
Loading layer add to dp0_server2[1], gpu1[1]
Loading layer layer1_0_relu_2 to dp0_server2[2], gpu1[2]
Loading layer layer1_1_conv1 to dp0_server2[3], gpu2[0]
Loading layer layer1_1_bn1 to dp0_server2[4], gpu2[1]
Loading layer layer1_1_relu to dp0_server2[5], gpu3[0]
Loading layer layer1_1_conv2 to dp0_server2[6], gpu3[1]
Loading layer layer1_1_bn2 to dp0_server2[7], gpu3[2]
Loading layer layer1_1_relu_1 to dp0_server2[8], gpu4[0]
Loading layer layer1_1_conv3 to dp0_server2[9], gpu4[1]
Loading layer layer1_1_bn3 to dp0_server2[10], gpu4[2]
Loading layer add_1 to dp0_server2[11], gpu4[3]
    global_index  layer_index                   name                                   args  input_#  output_#  Param_#  dp_index  pp_index  tp_index         opcode                   target   layer_type                     input_shape                    output_shape                  param_shape                                                                                                           kwargs  dtype_size direction  avg_mem_grp_idx  avg_mem_grp_size  min_comm_grp_id  min_comm_grp_sum  min_comm_grp_last_weight  compute_density_ops    server_id gpu_id  index_on_host  index_on_GPU input_source output_dest  prev_server prev_gpu  next_server next_gpu     read_time     exec_time    write_time
0            100            0                      x                                     ()      100       100        0         0         0         0    placeholder                        x         None   torch.Size([32, 3, 224, 224])  torch.Size([32, 64, 112, 112])                         None                                                                                                             None           4       FWD                0                 0                0                 0                         0                10000  dp0_server1   gpu1              0             0         host         HBM         None     None  dp0_server1     gpu1  5.820766e-09  5.128205e-10  2.395685e-10
1            101            1                  conv1                                   (x,)     7840    576000      576         0         0         0    call_module                    conv1       Conv2d  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])    torch.Size([64, 3, 7, 7])                                                             {'stride': (2, 2), 'padding': (3, 3), 'bias': False}           4       FWD                0                 0                0                 0                         0                11000  dp0_server1   gpu1              1             1          HBM         HBM  dp0_server1     gpu1  dp0_server1     gpu1  1.878217e-08  5.641026e-10  1.379915e-06
2            102            2                    bn1                               (conv1,)   576000    576000      128         0         0         0    call_module                      bn1  BatchNorm2d  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                0                 0                0                 0                         0                12000  dp0_server1   gpu1              2             2          HBM         HBM  dp0_server1     gpu1  dp0_server1     gpu1  1.379915e-06  6.153846e-10  1.379915e-06
3            103            3                   relu                                 (bn1,)   576000    576000        0         0         0         0    call_module                     relu         ReLU  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])                         None                                                                                                {'inplace': True}           4       FWD                0                 0                0                 0                         0                13000  dp0_server1   gpu1              3             3          HBM     peerGPU  dp0_server1     gpu1  dp0_server1     gpu2  1.379915e-06  6.666667e-10  3.576279e-06
4            104            4                maxpool                                (relu,)   576000    144000        0         0         0         0    call_module                  maxpool    MaxPool2d  torch.Size([32, 64, 112, 112])    torch.Size([32, 64, 56, 56])                         None                                 {'kernel_size': 3, 'stride': 2, 'padding': 1, 'dilation': 1, 'ceil_mode': False}           4       FWD                1                 0                0                 0                         0                14000  dp0_server1   gpu2              4             0      peerGPU         HBM  dp0_server1     gpu1  dp0_server1     gpu2  3.576279e-06  7.179487e-10  3.449787e-07
5            105            5         layer1_0_conv1                             (maxpool,)   144000    144000     4096         0         0         0    call_module           layer1.0.conv1       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                1                 0                0                 0                         0                15000  dp0_server1   gpu2              5             1          HBM         HBM  dp0_server1     gpu2  dp0_server1     gpu2  3.449787e-07  7.692308e-10  3.449787e-07
6            106            6           layer1_0_bn1                      (layer1_0_conv1,)   144000    144000      128         0         0         0    call_module             layer1.0.bn1  BatchNorm2d   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                1                 0                0                 0                         0                16000  dp0_server1   gpu2              6             2          HBM         HBM  dp0_server1     gpu2  dp0_server1     gpu2  3.449787e-07  8.205128e-10  3.449787e-07
7            107            7          layer1_0_relu                        (layer1_0_bn1,)   144000    144000        0         0         0         0    call_module            layer1.0.relu         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                1                 0                0                 0                         0                17000  dp0_server1   gpu2              7             3          HBM     peerGPU  dp0_server1     gpu2  dp0_server1     gpu3  3.449787e-07  8.717949e-10  8.940697e-07
8            108            8         layer1_0_conv2                       (layer1_0_relu,)   144000    144000    36864         0         0         0    call_module           layer1.0.conv2       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 3, 3])  {'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                2                 0                0                 0                         0                18000  dp0_server1   gpu3              8             0      peerGPU         HBM  dp0_server1     gpu2  dp0_server1     gpu3  8.940697e-07  9.230769e-10  3.449787e-07
9            109            9           layer1_0_bn2                      (layer1_0_conv2,)   144000    144000      128         0         0         0    call_module             layer1.0.bn2  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                2                 0                0                 0                         0                19000  dp0_server1   gpu3              9             1          HBM         HBM  dp0_server1     gpu3  dp0_server1     gpu3  3.449787e-07  9.743590e-10  3.449787e-07
10           110           10        layer1_0_relu_1                        (layer1_0_bn2,)   144000    144000        0         0         0         0    call_module          layer1.0.relu_1         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                2                 0                0                 0                         0                20000  dp0_server1   gpu3             10             2          HBM         HBM  dp0_server1     gpu3  dp0_server1     gpu3  3.449787e-07  1.025641e-09  3.449787e-07
11           111           11         layer1_0_conv3                     (layer1_0_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.0.conv3       Conv2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                2                 0                0                 0                         0                21000  dp0_server1   gpu3             11             3          HBM     peerGPU  dp0_server1     gpu3  dp0_server1     gpu4  3.449787e-07  1.076923e-09  3.576279e-06
12           112           12           layer1_0_bn3                      (layer1_0_conv3,)   576000    576000      512         0         0         0    call_module             layer1.0.bn3  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                3                 0                0                 0                         0                22000  dp0_server1   gpu4             12             0      peerGPU         HBM  dp0_server1     gpu3  dp0_server1     gpu4  3.576279e-06  1.128205e-09  1.379915e-06
13           113           13  layer1_0_downsample_0               (layer1_0_downsample_0,)   576000    576000    16384         0         0         0    call_module    layer1.0.downsample.0       Conv2d    torch.Size([32, 64, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (2, 2), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                3                 0                0                 0                         0                23000  dp0_server1   gpu4             13             1          HBM     network  dp0_server1     gpu4  dp0_server2     gpu1  1.379915e-06  1.179487e-09  3.352761e-05
14           114           14  layer1_0_downsample_1               (layer1_0_downsample_1,)   576000    576000      512         0         0         0    call_module    layer1.0.downsample.1  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                4                 0                0                 0                         0                24000  dp0_server2   gpu1              0             0      network         HBM  dp0_server1     gpu4  dp0_server2     gpu1  3.352761e-05  1.230769e-09  1.379915e-06
15           115           15                    add  (layer1_0_bn3, layer1_0_downsample_1)   576000    576000        0         0         0         0  call_function  <built-in function add>       Tensor   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                             None           4       FWD                4                 0                0                 0                         0                25000  dp0_server2   gpu1              1             1          HBM         HBM  dp0_server2     gpu1  dp0_server2     gpu1  1.379915e-06  1.282051e-09  1.379915e-06
16           116           16        layer1_0_relu_2                                 (add,)   576000    576000        0         0         0         0    call_module            layer1.0.relu         ReLU   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                4                 0                0                 0                         0                26000  dp0_server2   gpu1              2             2          HBM     peerGPU  dp0_server2     gpu1  dp0_server2     gpu2  1.379915e-06  1.333333e-09  3.576279e-06
17           117           17         layer1_1_conv1                     (layer1_0_relu_2,)   144000    144000    16384         0         0         0    call_module           layer1.1.conv1       Conv2d   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                5                 0                0                 0                         0                27000  dp0_server2   gpu2              3             0      peerGPU         HBM  dp0_server2     gpu1  dp0_server2     gpu2  8.940697e-07  1.384615e-09  3.449787e-07
18           118           18           layer1_1_bn1                      (layer1_1_conv1,)   144000    144000      128         0         0         0    call_module             layer1.1.bn1  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                5                 0                0                 0                         0                28000  dp0_server2   gpu2              4             1          HBM     peerGPU  dp0_server2     gpu2  dp0_server2     gpu3  3.449787e-07  1.435897e-09  8.940697e-07
19           119           19          layer1_1_relu                        (layer1_1_bn1,)   144000    144000        0         0         0         0    call_module            layer1.1.relu         ReLU   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                6                 0                0                 0                         0                29000  dp0_server2   gpu3              5             0      peerGPU         HBM  dp0_server2     gpu2  dp0_server2     gpu3  8.940697e-07  1.487179e-09  3.449787e-07
20           120           20         layer1_1_conv2                       (layer1_1_relu,)   144000    144000    36864         0         0         0    call_module           layer1.1.conv2       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 3, 3])  {'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                6                 0                0                 0                         0                30000  dp0_server2   gpu3              6             1          HBM         HBM  dp0_server2     gpu3  dp0_server2     gpu3  3.449787e-07  1.538462e-09  3.449787e-07
21           121           21           layer1_1_bn2                      (layer1_1_conv2,)   144000    144000      128         0         0         0    call_module             layer1.1.bn2  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                6                 0                0                 0                         0                31000  dp0_server2   gpu3              7             2          HBM     peerGPU  dp0_server2     gpu3  dp0_server2     gpu4  3.449787e-07  1.589744e-09  8.940697e-07
22           122           22        layer1_1_relu_1                        (layer1_1_bn2,)   144000    144000        0         0         0         0    call_module          layer1.1.relu_1         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                7                 0                0                 0                         0                32000  dp0_server2   gpu4              8             0      peerGPU         HBM  dp0_server2     gpu3  dp0_server2     gpu4  8.940697e-07  1.641026e-09  3.449787e-07
23           123           23         layer1_1_conv3                     (layer1_1_relu_1,)   576000    576000    16384         0         0         0    call_module           layer1.1.conv3       Conv2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                7                 0                0                 0                         0                33000  dp0_server2   gpu4              9             1          HBM         HBM  dp0_server2     gpu4  dp0_server2     gpu4  1.379915e-06  1.692308e-09  1.379915e-06
24           124           24           layer1_1_bn3                      (layer1_1_conv3,)   576000    576000      512         0         0         0    call_module             layer1.1.bn3  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                7                 0                0                 0                         0                34000  dp0_server2   gpu4             10             2          HBM         HBM  dp0_server2     gpu4  dp0_server2     gpu4  1.379915e-06  1.743590e-09  1.379915e-06
25           125           25                  add_1                        (layer1_1_bn3,)   576000    576000        0         0         0         0  call_function  <built-in function add>       Tensor   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                             None           4       FWD                7                 0                0                 0                         0                35000  dp0_server2   gpu4             11             3          HBM         HBM  dp0_server2     gpu4         None     None  1.379915e-06  1.794872e-09  1.379915e-06

Loading layer x to dp1_server1[0], gpu1[0]
Loading layer conv1 to dp1_server1[1], gpu1[1]
Loading layer bn1 to dp1_server1[2], gpu1[2]
Loading layer relu to dp1_server1[3], gpu1[3]
Loading layer maxpool to dp1_server1[4], gpu2[0]
Loading layer layer1_0_conv1 to dp1_server1[5], gpu2[1]
Loading layer layer1_0_bn1 to dp1_server1[6], gpu2[2]
Loading layer layer1_0_relu to dp1_server1[7], gpu2[3]
Loading layer layer1_0_conv2 to dp1_server1[8], gpu3[0]
Loading layer layer1_0_bn2 to dp1_server1[9], gpu3[1]
Loading layer layer1_0_relu_1 to dp1_server1[10], gpu3[2]
Loading layer layer1_0_conv3 to dp1_server1[11], gpu3[3]
Loading layer layer1_0_bn3 to dp1_server1[12], gpu4[0]
Loading layer layer1_0_downsample_0 to dp1_server1[13], gpu4[1]
Loading layer layer1_0_downsample_1 to dp1_server2[0], gpu1[0]
Loading layer add to dp1_server2[1], gpu1[1]
Loading layer layer1_0_relu_2 to dp1_server2[2], gpu1[2]
Loading layer layer1_1_conv1 to dp1_server2[3], gpu2[0]
Loading layer layer1_1_bn1 to dp1_server2[4], gpu2[1]
Loading layer layer1_1_relu to dp1_server2[5], gpu3[0]
Loading layer layer1_1_conv2 to dp1_server2[6], gpu3[1]
Loading layer layer1_1_bn2 to dp1_server2[7], gpu3[2]
Loading layer layer1_1_relu_1 to dp1_server2[8], gpu4[0]
Loading layer layer1_1_conv3 to dp1_server2[9], gpu4[1]
Loading layer layer1_1_bn3 to dp1_server2[10], gpu4[2]
Loading layer add_1 to dp1_server2[11], gpu4[3]
    global_index  layer_index                   name                                   args  input_#  output_#  Param_#  dp_index  pp_index  tp_index         opcode                   target   layer_type                     input_shape                    output_shape                  param_shape                                                                                                           kwargs  dtype_size direction  avg_mem_grp_idx  avg_mem_grp_size  min_comm_grp_id  min_comm_grp_sum  min_comm_grp_last_weight  compute_density_ops    server_id gpu_id  index_on_host  index_on_GPU input_source output_dest  prev_server prev_gpu  next_server next_gpu     read_time     exec_time    write_time
0            100            0                      x                                     ()      100       100        0         0         0         0    placeholder                        x         None   torch.Size([32, 3, 224, 224])  torch.Size([32, 64, 112, 112])                         None                                                                                                             None           4       FWD                0                 0                0                 0                         0                10000  dp1_server1   gpu1              0             0         host         HBM         None     None  dp1_server1     gpu1  5.820766e-09  5.128205e-10  2.395685e-10
1            101            1                  conv1                                   (x,)     7840    576000      576         0         0         0    call_module                    conv1       Conv2d  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])    torch.Size([64, 3, 7, 7])                                                             {'stride': (2, 2), 'padding': (3, 3), 'bias': False}           4       FWD                0                 0                0                 0                         0                11000  dp1_server1   gpu1              1             1          HBM         HBM  dp1_server1     gpu1  dp1_server1     gpu1  1.878217e-08  5.641026e-10  1.379915e-06
2            102            2                    bn1                               (conv1,)   576000    576000      128         0         0         0    call_module                      bn1  BatchNorm2d  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                0                 0                0                 0                         0                12000  dp1_server1   gpu1              2             2          HBM         HBM  dp1_server1     gpu1  dp1_server1     gpu1  1.379915e-06  6.153846e-10  1.379915e-06
3            103            3                   relu                                 (bn1,)   576000    576000        0         0         0         0    call_module                     relu         ReLU  torch.Size([32, 64, 112, 112])  torch.Size([32, 64, 112, 112])                         None                                                                                                {'inplace': True}           4       FWD                0                 0                0                 0                         0                13000  dp1_server1   gpu1              3             3          HBM     peerGPU  dp1_server1     gpu1  dp1_server1     gpu2  1.379915e-06  6.666667e-10  3.576279e-06
4            104            4                maxpool                                (relu,)   576000    144000        0         0         0         0    call_module                  maxpool    MaxPool2d  torch.Size([32, 64, 112, 112])    torch.Size([32, 64, 56, 56])                         None                                 {'kernel_size': 3, 'stride': 2, 'padding': 1, 'dilation': 1, 'ceil_mode': False}           4       FWD                1                 0                0                 0                         0                14000  dp1_server1   gpu2              4             0      peerGPU         HBM  dp1_server1     gpu1  dp1_server1     gpu2  3.576279e-06  7.179487e-10  3.449787e-07
5            105            5         layer1_0_conv1                             (maxpool,)   144000    144000     4096         0         0         0    call_module           layer1.0.conv1       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                1                 0                0                 0                         0                15000  dp1_server1   gpu2              5             1          HBM         HBM  dp1_server1     gpu2  dp1_server1     gpu2  3.449787e-07  7.692308e-10  3.449787e-07
6            106            6           layer1_0_bn1                      (layer1_0_conv1,)   144000    144000      128         0         0         0    call_module             layer1.0.bn1  BatchNorm2d   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                1                 0                0                 0                         0                16000  dp1_server1   gpu2              6             2          HBM         HBM  dp1_server1     gpu2  dp1_server1     gpu2  3.449787e-07  8.205128e-10  3.449787e-07
7            107            7          layer1_0_relu                        (layer1_0_bn1,)   144000    144000        0         0         0         0    call_module            layer1.0.relu         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                1                 0                0                 0                         0                17000  dp1_server1   gpu2              7             3          HBM     peerGPU  dp1_server1     gpu2  dp1_server1     gpu3  3.449787e-07  8.717949e-10  8.940697e-07
8            108            8         layer1_0_conv2                       (layer1_0_relu,)   144000    144000    36864         0         0         0    call_module           layer1.0.conv2       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 3, 3])  {'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                2                 0                0                 0                         0                18000  dp1_server1   gpu3              8             0      peerGPU         HBM  dp1_server1     gpu2  dp1_server1     gpu3  8.940697e-07  9.230769e-10  3.449787e-07
9            109            9           layer1_0_bn2                      (layer1_0_conv2,)   144000    144000      128         0         0         0    call_module             layer1.0.bn2  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                2                 0                0                 0                         0                19000  dp1_server1   gpu3              9             1          HBM         HBM  dp1_server1     gpu3  dp1_server1     gpu3  3.449787e-07  9.743590e-10  3.449787e-07
10           110           10        layer1_0_relu_1                        (layer1_0_bn2,)   144000    144000        0         0         0         0    call_module          layer1.0.relu_1         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                2                 0                0                 0                         0                20000  dp1_server1   gpu3             10             2          HBM         HBM  dp1_server1     gpu3  dp1_server1     gpu3  3.449787e-07  1.025641e-09  3.449787e-07
11           111           11         layer1_0_conv3                     (layer1_0_relu_1,)   144000    576000    16384         0         0         0    call_module           layer1.0.conv3       Conv2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                2                 0                0                 0                         0                21000  dp1_server1   gpu3             11             3          HBM     peerGPU  dp1_server1     gpu3  dp1_server1     gpu4  3.449787e-07  1.076923e-09  3.576279e-06
12           112           12           layer1_0_bn3                      (layer1_0_conv3,)   576000    576000      512         0         0         0    call_module             layer1.0.bn3  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                3                 0                0                 0                         0                22000  dp1_server1   gpu4             12             0      peerGPU         HBM  dp1_server1     gpu3  dp1_server1     gpu4  3.576279e-06  1.128205e-09  1.379915e-06
13           113           13  layer1_0_downsample_0               (layer1_0_downsample_0,)   576000    576000    16384         0         0         0    call_module    layer1.0.downsample.0       Conv2d    torch.Size([32, 64, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (2, 2), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                3                 0                0                 0                         0                23000  dp1_server1   gpu4             13             1          HBM     network  dp1_server1     gpu4  dp1_server2     gpu1  1.379915e-06  1.179487e-09  3.352761e-05
14           114           14  layer1_0_downsample_1               (layer1_0_downsample_1,)   576000    576000      512         0         0         0    call_module    layer1.0.downsample.1  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                4                 0                0                 0                         0                24000  dp1_server2   gpu1              0             0      network         HBM  dp1_server1     gpu4  dp1_server2     gpu1  3.352761e-05  1.230769e-09  1.379915e-06
15           115           15                    add  (layer1_0_bn3, layer1_0_downsample_1)   576000    576000        0         0         0         0  call_function  <built-in function add>       Tensor   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                             None           4       FWD                4                 0                0                 0                         0                25000  dp1_server2   gpu1              1             1          HBM         HBM  dp1_server2     gpu1  dp1_server2     gpu1  1.379915e-06  1.282051e-09  1.379915e-06
16           116           16        layer1_0_relu_2                                 (add,)   576000    576000        0         0         0         0    call_module            layer1.0.relu         ReLU   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                4                 0                0                 0                         0                26000  dp1_server2   gpu1              2             2          HBM     peerGPU  dp1_server2     gpu1  dp1_server2     gpu2  1.379915e-06  1.333333e-09  3.576279e-06
17           117           17         layer1_1_conv1                     (layer1_0_relu_2,)   144000    144000    16384         0         0         0    call_module           layer1.1.conv1       Conv2d   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                5                 0                0                 0                         0                27000  dp1_server2   gpu2              3             0      peerGPU         HBM  dp1_server2     gpu1  dp1_server2     gpu2  8.940697e-07  1.384615e-09  3.449787e-07
18           118           18           layer1_1_bn1                      (layer1_1_conv1,)   144000    144000      128         0         0         0    call_module             layer1.1.bn1  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                5                 0                0                 0                         0                28000  dp1_server2   gpu2              4             1          HBM     peerGPU  dp1_server2     gpu2  dp1_server2     gpu3  3.449787e-07  1.435897e-09  8.940697e-07
19           119           19          layer1_1_relu                        (layer1_1_bn1,)   144000    144000        0         0         0         0    call_module            layer1.1.relu         ReLU   torch.Size([32, 256, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                6                 0                0                 0                         0                29000  dp1_server2   gpu3              5             0      peerGPU         HBM  dp1_server2     gpu2  dp1_server2     gpu3  8.940697e-07  1.487179e-09  3.449787e-07
20           120           20         layer1_1_conv2                       (layer1_1_relu,)   144000    144000    36864         0         0         0    call_module           layer1.1.conv2       Conv2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])   torch.Size([64, 64, 3, 3])  {'kernel_size': (3, 3), 'stride': (1, 1), 'padding': (1, 1), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                6                 0                0                 0                         0                30000  dp1_server2   gpu3              6             1          HBM         HBM  dp1_server2     gpu3  dp1_server2     gpu3  3.449787e-07  1.538462e-09  3.449787e-07
21           121           21           layer1_1_bn2                      (layer1_1_conv2,)   144000    144000      128         0         0         0    call_module             layer1.1.bn2  BatchNorm2d    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])             torch.Size([64])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                6                 0                0                 0                         0                31000  dp1_server2   gpu3              7             2          HBM     peerGPU  dp1_server2     gpu3  dp1_server2     gpu4  3.449787e-07  1.589744e-09  8.940697e-07
22           122           22        layer1_1_relu_1                        (layer1_1_bn2,)   144000    144000        0         0         0         0    call_module          layer1.1.relu_1         ReLU    torch.Size([32, 64, 56, 56])    torch.Size([32, 64, 56, 56])                         None                                                                                                {'inplace': True}           4       FWD                7                 0                0                 0                         0                32000  dp1_server2   gpu4              8             0      peerGPU         HBM  dp1_server2     gpu3  dp1_server2     gpu4  8.940697e-07  1.641026e-09  3.449787e-07
23           123           23         layer1_1_conv3                     (layer1_1_relu_1,)   576000    576000    16384         0         0         0    call_module           layer1.1.conv3       Conv2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])  torch.Size([256, 64, 1, 1])  {'kernel_size': (1, 1), 'stride': (1, 1), 'padding': (0, 0), 'dilation': (1, 1), 'groups': (1,), 'bias': False}           4       FWD                7                 0                0                 0                         0                33000  dp1_server2   gpu4              9             1          HBM         HBM  dp1_server2     gpu4  dp1_server2     gpu4  1.379915e-06  1.692308e-09  1.379915e-06
24           124           24           layer1_1_bn3                      (layer1_1_conv3,)   576000    576000      512         0         0         0    call_module             layer1.1.bn3  BatchNorm2d   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])            torch.Size([256])                                     {'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True}           4       FWD                7                 0                0                 0                         0                34000  dp1_server2   gpu4             10             2          HBM         HBM  dp1_server2     gpu4  dp1_server2     gpu4  1.379915e-06  1.743590e-09  1.379915e-06
25           125           25                  add_1                        (layer1_1_bn3,)   576000    576000        0         0         0         0  call_function  <built-in function add>       Tensor   torch.Size([32, 256, 56, 56])   torch.Size([32, 256, 56, 56])                         None                                                                                                             None           4       FWD                7                 0                0                 0                         0                35000  dp1_server2   gpu4             11             3          HBM         HBM  dp1_server2     gpu4         None     None  1.379915e-06  1.794872e-09  1.379915e-06

DP group 0
{'server_id': 'dp0_server1', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7fc715e2ae50>), ('gpu2', <__main__.GPU object at 0x7fc715e2afa0>), ('gpu3', <__main__.GPU object at 0x7fc715e49070>), ('gpu4', <__main__.GPU object at 0x7fc715e49160>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7fc715e491c0>), ('net2', <__main__.NetworkCard object at 0x7fc715e49250>), ('net3', <__main__.NetworkCard object at 0x7fc715e492e0>), ('net4', <__main__.NetworkCard object at 0x7fc715e49370>)]), 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54430>), (1, <__main__.Layer object at 0x7fc715e543d0>), (2, <__main__.Layer object at 0x7fc715e54580>), (3, <__main__.Layer object at 0x7fc715e54550>), (4, <__main__.Layer object at 0x7fc715e542e0>), (5, <__main__.Layer object at 0x7fc715e544f0>), (6, <__main__.Layer object at 0x7fc715e54490>), (7, <__main__.Layer object at 0x7fc715e54460>), (8, <__main__.Layer object at 0x7fc715e545e0>), (9, <__main__.Layer object at 0x7fc715e546a0>), (10, <__main__.Layer object at 0x7fc715e546d0>), (11, <__main__.Layer object at 0x7fc715e54700>), (12, <__main__.Layer object at 0x7fc715e54730>), (13, <__main__.Layer object at 0x7fc715e54760>)]), 'min_layer_index': 0, 'max_layer_index': 13}
{'server': <__main__.Server object at 0x7fc718f47f40>, 'gpu_id': 'gpu1', 'server_id': 'dp0_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54430>), (1, <__main__.Layer object at 0x7fc715e543d0>), (2, <__main__.Layer object at 0x7fc715e54580>), (3, <__main__.Layer object at 0x7fc715e54550>)]), 'model_size': 2816, 'min_layer_index': 0, 'max_layer_index': 3}
{'server': <__main__.Server object at 0x7fc718f47f40>, 'gpu_id': 'gpu2', 'server_id': 'dp0_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e542e0>), (1, <__main__.Layer object at 0x7fc715e544f0>), (2, <__main__.Layer object at 0x7fc715e54490>), (3, <__main__.Layer object at 0x7fc715e54460>)]), 'model_size': 16896, 'min_layer_index': 4, 'max_layer_index': 7}
{'server': <__main__.Server object at 0x7fc718f47f40>, 'gpu_id': 'gpu3', 'server_id': 'dp0_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e545e0>), (1, <__main__.Layer object at 0x7fc715e546a0>), (2, <__main__.Layer object at 0x7fc715e546d0>), (3, <__main__.Layer object at 0x7fc715e54700>)]), 'model_size': 213504, 'min_layer_index': 8, 'max_layer_index': 11}
{'server': <__main__.Server object at 0x7fc718f47f40>, 'gpu_id': 'gpu4', 'server_id': 'dp0_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54730>), (1, <__main__.Layer object at 0x7fc715e54760>)]), 'model_size': 67584, 'min_layer_index': 12, 'max_layer_index': 13}
{'server': <__main__.Server object at 0x7fc718f47f40>, 'network_card_id': 'net1', 'server_id': 'dp0_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc718f47f40>, 'network_card_id': 'net2', 'server_id': 'dp0_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc718f47f40>, 'network_card_id': 'net3', 'server_id': 'dp0_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc718f47f40>, 'network_card_id': 'net4', 'server_id': 'dp0_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp0_server2', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7fc715e494f0>), ('gpu2', <__main__.GPU object at 0x7fc715e495e0>), ('gpu3', <__main__.GPU object at 0x7fc715e496d0>), ('gpu4', <__main__.GPU object at 0x7fc715e497c0>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7fc715e49820>), ('net2', <__main__.NetworkCard object at 0x7fc715e498b0>), ('net3', <__main__.NetworkCard object at 0x7fc715e49940>), ('net4', <__main__.NetworkCard object at 0x7fc715e499d0>)]), 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54790>), (1, <__main__.Layer object at 0x7fc715e547c0>), (2, <__main__.Layer object at 0x7fc715e547f0>), (3, <__main__.Layer object at 0x7fc715e54820>), (4, <__main__.Layer object at 0x7fc715e54850>), (5, <__main__.Layer object at 0x7fc715e54880>), (6, <__main__.Layer object at 0x7fc715e548b0>), (7, <__main__.Layer object at 0x7fc715e548e0>), (8, <__main__.Layer object at 0x7fc715e54910>), (9, <__main__.Layer object at 0x7fc715e54940>), (10, <__main__.Layer object at 0x7fc715e54970>), (11, <__main__.Layer object at 0x7fc715e549a0>)]), 'min_layer_index': 14, 'max_layer_index': 25}
{'server': <__main__.Server object at 0x7fc715e49190>, 'gpu_id': 'gpu1', 'server_id': 'dp0_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54790>), (1, <__main__.Layer object at 0x7fc715e547c0>), (2, <__main__.Layer object at 0x7fc715e547f0>)]), 'model_size': 2048, 'min_layer_index': 14, 'max_layer_index': 16}
{'server': <__main__.Server object at 0x7fc715e49190>, 'gpu_id': 'gpu2', 'server_id': 'dp0_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54820>), (1, <__main__.Layer object at 0x7fc715e54850>)]), 'model_size': 66048, 'min_layer_index': 17, 'max_layer_index': 18}
{'server': <__main__.Server object at 0x7fc715e49190>, 'gpu_id': 'gpu3', 'server_id': 'dp0_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54880>), (1, <__main__.Layer object at 0x7fc715e548b0>), (2, <__main__.Layer object at 0x7fc715e548e0>)]), 'model_size': 147968, 'min_layer_index': 19, 'max_layer_index': 21}
{'server': <__main__.Server object at 0x7fc715e49190>, 'gpu_id': 'gpu4', 'server_id': 'dp0_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54910>), (1, <__main__.Layer object at 0x7fc715e54940>), (2, <__main__.Layer object at 0x7fc715e54970>), (3, <__main__.Layer object at 0x7fc715e549a0>)]), 'model_size': 67584, 'min_layer_index': 22, 'max_layer_index': 25}
{'server': <__main__.Server object at 0x7fc715e49190>, 'network_card_id': 'net1', 'server_id': 'dp0_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e49190>, 'network_card_id': 'net2', 'server_id': 'dp0_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e49190>, 'network_card_id': 'net3', 'server_id': 'dp0_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e49190>, 'network_card_id': 'net4', 'server_id': 'dp0_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp0_server3', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7fc715e49b50>), ('gpu2', <__main__.GPU object at 0x7fc715e49c40>), ('gpu3', <__main__.GPU object at 0x7fc715e49d30>), ('gpu4', <__main__.GPU object at 0x7fc715e49e20>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7fc715e49e80>), ('net2', <__main__.NetworkCard object at 0x7fc715e49f10>), ('net3', <__main__.NetworkCard object at 0x7fc715e49fa0>), ('net4', <__main__.NetworkCard object at 0x7fc715e4c070>)]), 'model_layers': OrderedDict(), 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e497f0>, 'gpu_id': 'gpu1', 'server_id': 'dp0_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e497f0>, 'gpu_id': 'gpu2', 'server_id': 'dp0_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e497f0>, 'gpu_id': 'gpu3', 'server_id': 'dp0_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e497f0>, 'gpu_id': 'gpu4', 'server_id': 'dp0_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e497f0>, 'network_card_id': 'net1', 'server_id': 'dp0_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e497f0>, 'network_card_id': 'net2', 'server_id': 'dp0_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e497f0>, 'network_card_id': 'net3', 'server_id': 'dp0_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e497f0>, 'network_card_id': 'net4', 'server_id': 'dp0_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp0_server4', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7fc715e4c1f0>), ('gpu2', <__main__.GPU object at 0x7fc715e4c2e0>), ('gpu3', <__main__.GPU object at 0x7fc715e4c3d0>), ('gpu4', <__main__.GPU object at 0x7fc715e4c4c0>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7fc715e4c520>), ('net2', <__main__.NetworkCard object at 0x7fc715e4c5b0>), ('net3', <__main__.NetworkCard object at 0x7fc715e4c640>), ('net4', <__main__.NetworkCard object at 0x7fc715e4c6d0>)]), 'model_layers': OrderedDict(), 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e49e50>, 'gpu_id': 'gpu1', 'server_id': 'dp0_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e49e50>, 'gpu_id': 'gpu2', 'server_id': 'dp0_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e49e50>, 'gpu_id': 'gpu3', 'server_id': 'dp0_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e49e50>, 'gpu_id': 'gpu4', 'server_id': 'dp0_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e49e50>, 'network_card_id': 'net1', 'server_id': 'dp0_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e49e50>, 'network_card_id': 'net2', 'server_id': 'dp0_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e49e50>, 'network_card_id': 'net3', 'server_id': 'dp0_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e49e50>, 'network_card_id': 'net4', 'server_id': 'dp0_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
DP group 1
{'server_id': 'dp1_server1', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7fc715e4c850>), ('gpu2', <__main__.GPU object at 0x7fc715e4c940>), ('gpu3', <__main__.GPU object at 0x7fc715e4ca30>), ('gpu4', <__main__.GPU object at 0x7fc715e4cb20>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7fc715e4cb80>), ('net2', <__main__.NetworkCard object at 0x7fc715e4cc10>), ('net3', <__main__.NetworkCard object at 0x7fc715e4cca0>), ('net4', <__main__.NetworkCard object at 0x7fc715e4cd30>)]), 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54a00>), (1, <__main__.Layer object at 0x7fc715e54a30>), (2, <__main__.Layer object at 0x7fc715e54ac0>), (3, <__main__.Layer object at 0x7fc715e54a90>), (4, <__main__.Layer object at 0x7fc715e54b20>), (5, <__main__.Layer object at 0x7fc715e54af0>), (6, <__main__.Layer object at 0x7fc715e54400>), (7, <__main__.Layer object at 0x7fc715e54310>), (8, <__main__.Layer object at 0x7fc715e54b50>), (9, <__main__.Layer object at 0x7fc715e54b80>), (10, <__main__.Layer object at 0x7fc715e54bb0>), (11, <__main__.Layer object at 0x7fc715e54be0>), (12, <__main__.Layer object at 0x7fc715e54c10>), (13, <__main__.Layer object at 0x7fc715e54c40>)]), 'min_layer_index': 0, 'max_layer_index': 13}
{'server': <__main__.Server object at 0x7fc718e234c0>, 'gpu_id': 'gpu1', 'server_id': 'dp1_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54a00>), (1, <__main__.Layer object at 0x7fc715e54a30>), (2, <__main__.Layer object at 0x7fc715e54ac0>), (3, <__main__.Layer object at 0x7fc715e54a90>)]), 'model_size': 2816, 'min_layer_index': 0, 'max_layer_index': 3}
{'server': <__main__.Server object at 0x7fc718e234c0>, 'gpu_id': 'gpu2', 'server_id': 'dp1_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54b20>), (1, <__main__.Layer object at 0x7fc715e54af0>), (2, <__main__.Layer object at 0x7fc715e54400>), (3, <__main__.Layer object at 0x7fc715e54310>)]), 'model_size': 16896, 'min_layer_index': 4, 'max_layer_index': 7}
{'server': <__main__.Server object at 0x7fc718e234c0>, 'gpu_id': 'gpu3', 'server_id': 'dp1_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54b50>), (1, <__main__.Layer object at 0x7fc715e54b80>), (2, <__main__.Layer object at 0x7fc715e54bb0>), (3, <__main__.Layer object at 0x7fc715e54be0>)]), 'model_size': 213504, 'min_layer_index': 8, 'max_layer_index': 11}
{'server': <__main__.Server object at 0x7fc718e234c0>, 'gpu_id': 'gpu4', 'server_id': 'dp1_server1', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54c10>), (1, <__main__.Layer object at 0x7fc715e54c40>)]), 'model_size': 67584, 'min_layer_index': 12, 'max_layer_index': 13}
{'server': <__main__.Server object at 0x7fc718e234c0>, 'network_card_id': 'net1', 'server_id': 'dp1_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc718e234c0>, 'network_card_id': 'net2', 'server_id': 'dp1_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc718e234c0>, 'network_card_id': 'net3', 'server_id': 'dp1_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc718e234c0>, 'network_card_id': 'net4', 'server_id': 'dp1_server1', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp1_server2', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7fc715e4ceb0>), ('gpu2', <__main__.GPU object at 0x7fc715e4cfa0>), ('gpu3', <__main__.GPU object at 0x7fc715e510d0>), ('gpu4', <__main__.GPU object at 0x7fc715e511c0>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7fc715e51220>), ('net2', <__main__.NetworkCard object at 0x7fc715e512b0>), ('net3', <__main__.NetworkCard object at 0x7fc715e51340>), ('net4', <__main__.NetworkCard object at 0x7fc715e513d0>)]), 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54cd0>), (1, <__main__.Layer object at 0x7fc715e54ca0>), (2, <__main__.Layer object at 0x7fc715e54d90>), (3, <__main__.Layer object at 0x7fc715e54d00>), (4, <__main__.Layer object at 0x7fc715e54df0>), (5, <__main__.Layer object at 0x7fc715e54d60>), (6, <__main__.Layer object at 0x7fc715e54520>), (7, <__main__.Layer object at 0x7fc715e54dc0>), (8, <__main__.Layer object at 0x7fc715e54e20>), (9, <__main__.Layer object at 0x7fc715e54e80>), (10, <__main__.Layer object at 0x7fc715e54eb0>), (11, <__main__.Layer object at 0x7fc715e54ee0>)]), 'min_layer_index': 14, 'max_layer_index': 25}
{'server': <__main__.Server object at 0x7fc715e4cb50>, 'gpu_id': 'gpu1', 'server_id': 'dp1_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54cd0>), (1, <__main__.Layer object at 0x7fc715e54ca0>), (2, <__main__.Layer object at 0x7fc715e54d90>)]), 'model_size': 2048, 'min_layer_index': 14, 'max_layer_index': 16}
{'server': <__main__.Server object at 0x7fc715e4cb50>, 'gpu_id': 'gpu2', 'server_id': 'dp1_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54d00>), (1, <__main__.Layer object at 0x7fc715e54df0>)]), 'model_size': 66048, 'min_layer_index': 17, 'max_layer_index': 18}
{'server': <__main__.Server object at 0x7fc715e4cb50>, 'gpu_id': 'gpu3', 'server_id': 'dp1_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54d60>), (1, <__main__.Layer object at 0x7fc715e54520>), (2, <__main__.Layer object at 0x7fc715e54dc0>)]), 'model_size': 147968, 'min_layer_index': 19, 'max_layer_index': 21}
{'server': <__main__.Server object at 0x7fc715e4cb50>, 'gpu_id': 'gpu4', 'server_id': 'dp1_server2', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict([(0, <__main__.Layer object at 0x7fc715e54e20>), (1, <__main__.Layer object at 0x7fc715e54e80>), (2, <__main__.Layer object at 0x7fc715e54eb0>), (3, <__main__.Layer object at 0x7fc715e54ee0>)]), 'model_size': 67584, 'min_layer_index': 22, 'max_layer_index': 25}
{'server': <__main__.Server object at 0x7fc715e4cb50>, 'network_card_id': 'net1', 'server_id': 'dp1_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e4cb50>, 'network_card_id': 'net2', 'server_id': 'dp1_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e4cb50>, 'network_card_id': 'net3', 'server_id': 'dp1_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e4cb50>, 'network_card_id': 'net4', 'server_id': 'dp1_server2', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp1_server3', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7fc715e51550>), ('gpu2', <__main__.GPU object at 0x7fc715e51640>), ('gpu3', <__main__.GPU object at 0x7fc715e51730>), ('gpu4', <__main__.GPU object at 0x7fc715e51820>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7fc715e51880>), ('net2', <__main__.NetworkCard object at 0x7fc715e51940>), ('net3', <__main__.NetworkCard object at 0x7fc715e519d0>), ('net4', <__main__.NetworkCard object at 0x7fc715e51a60>)]), 'model_layers': OrderedDict(), 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e511f0>, 'gpu_id': 'gpu1', 'server_id': 'dp1_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e511f0>, 'gpu_id': 'gpu2', 'server_id': 'dp1_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e511f0>, 'gpu_id': 'gpu3', 'server_id': 'dp1_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e511f0>, 'gpu_id': 'gpu4', 'server_id': 'dp1_server3', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e511f0>, 'network_card_id': 'net1', 'server_id': 'dp1_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e511f0>, 'network_card_id': 'net2', 'server_id': 'dp1_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e511f0>, 'network_card_id': 'net3', 'server_id': 'dp1_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e511f0>, 'network_card_id': 'net4', 'server_id': 'dp1_server3', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server_id': 'dp1_server4', 'pcie_version': '5.0', 'pcie_bandwidth_Bps': 137438953472, 'max_gpus': 4, 'max_network_cards': 4, 'gpus': OrderedDict([('gpu1', <__main__.GPU object at 0x7fc715e51be0>), ('gpu2', <__main__.GPU object at 0x7fc715e51d00>), ('gpu3', <__main__.GPU object at 0x7fc715e51df0>), ('gpu4', <__main__.GPU object at 0x7fc715e51ee0>)]), 'network_cards': OrderedDict([('net1', <__main__.NetworkCard object at 0x7fc715e51f40>), ('net2', <__main__.NetworkCard object at 0x7fc715e51ca0>), ('net3', <__main__.NetworkCard object at 0x7fc715e54040>), ('net4', <__main__.NetworkCard object at 0x7fc715e540d0>)]), 'model_layers': OrderedDict(), 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e51850>, 'gpu_id': 'gpu1', 'server_id': 'dp1_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net1', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e51850>, 'gpu_id': 'gpu2', 'server_id': 'dp1_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net2', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e51850>, 'gpu_id': 'gpu3', 'server_id': 'dp1_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net3', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e51850>, 'gpu_id': 'gpu4', 'server_id': 'dp1_server4', 'fp32_flops': 19500000000000.0, 'fp16_flops': 156000000000000.0, 'fp8_flops': 312000000000000.0, 'pcie_bandwidth_Bps': 68719476736, 'nvlink_supported': True, 'nvlink_bandwidth_Bps': 644245094400, 'memory_size_B': 42949672960, 'memory_bandwidth_Bps': 1669668536320, 'network_card_id': 'net4', 'model_layers': OrderedDict(), 'model_size': 0, 'min_layer_index': 1000000, 'max_layer_index': -1}
{'server': <__main__.Server object at 0x7fc715e51850>, 'network_card_id': 'net1', 'server_id': 'dp1_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e51850>, 'network_card_id': 'net2', 'server_id': 'dp1_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e51850>, 'network_card_id': 'net3', 'server_id': 'dp1_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
{'server': <__main__.Server object at 0x7fc715e51850>, 'network_card_id': 'net4', 'server_id': 'dp1_server4', 'pcie_bandwidth_Bps': 68719476736, 'network_bandwidth_bps': 400000000000}
